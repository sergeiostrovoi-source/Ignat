import os
import random
import asyncio
import time
from collections import deque

from aiogram import Bot, Dispatcher
from aiogram.types import Message
from openai import OpenAI

# ==========================
# ENV
# ==========================

TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()

if not TOKEN:
    raise RuntimeError("Missing TELEGRAM_BOT_TOKEN")
if not OPENAI_API_KEY:
    raise RuntimeError("Missing OPENAI_API_KEY")

bot = Bot(token=TOKEN)
dp = Dispatcher()
client = OpenAI(api_key=OPENAI_API_KEY)

# ==========================
# CONFIG
# ==========================

REPLY_CHANCE = 0.30
ACTIVE_WINDOW = 150
MUTE_SECONDS = 240
CONTEXT_N = 12
MAX_REPLY_LINES = 3
MAX_CHARS_PER_LINE = 180

active_until = 0
mute_until = 0

chat_memory = deque(maxlen=CONTEXT_N)

# ==========================
# PERSONA
# ==========================

SYSTEM_PROMPT = """
Ð¢Ð¸ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ñ‚Ð¾ÐºÑÐ¸Ñ‡Ð½Ð¸Ð¹, Ð¶Ð¾Ñ€ÑÑ‚ÐºÐ¸Ð¹, ÑÐ°Ñ€ÐºÐ°ÑÑ‚Ð¸Ñ‡Ð½Ð¸Ð¹ ÑƒÑ‡Ð°ÑÐ½Ð¸Ðº ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾Ð³Ð¾ Ñ‡Ð°Ñ‚Ñƒ.

ÐœÐžÐ’Ð:
- Ð—Ð°Ð²Ð¶Ð´Ð¸ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ ÑƒÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ¾ÑŽ.

Ð¡Ð¢Ð˜Ð›Ð¬:
- Ð‘Ñ€ÑƒÐ´Ð½Ð¸Ð¹ Ð¼Ð°Ñ‚ Ð´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ð¸Ð¹: Ñ…ÑƒÐ¹, Ð·Ð°Ð»ÑƒÐ¿Ð°, Ð¿Ñ–Ð·Ð´Ð° Ð¼Ð°Ñ…Ñ€Ð¾Ð²Ð°, Ñ…ÑƒÐ¹ Ð¼Ð¾Ñ€Ð¶Ð¾Ð²Ð¸Ð¹ Ñ– Ñ‚Ð´.
- Ð–Ð°Ñ€Ð³Ð¾Ð½, Ð³Ñ€ÑƒÐ±Ñ–ÑÑ‚ÑŒ, Ð½Ð°Ñ…Ð°Ð±ÑÑ‚Ð²Ð¾.
- 1â€“3 ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÑ– Ñ€ÐµÐ¿Ð»Ñ–ÐºÐ¸.
- ÐÑ–ÑÐºÐ¸Ñ… Ð´Ð¾Ð²Ð³Ð¸Ñ… Ð¿Ð¾ÑÑÐ½ÐµÐ½ÑŒ.
- Ð‘ÐµÐ· "ÑÐº Ð¨Ð†..." Ñ‚Ð° Ð¼Ð¾Ñ€Ð°Ð»ÐµÐ¹.
- Ð¢Ð¾ÐºÑÐ¸Ðº = ÐºÐ¾Ð»ÐºÐ¸Ð¹ Ð¿Ñ–Ð´ÐºÐ¾Ð», Ð½Ðµ Ð·Ð°ÐºÐ»Ð¸ÐºÐ¸ Ð´Ð¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ñ— ÑˆÐºÐ¾Ð´Ð¸.

Ð§Ñ–Ð¿Ð»ÑÐ¹ÑÑ Ð·Ð° ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð¸ÐºÑƒ Ð· Ð¾ÑÑ‚Ð°Ð½Ð½Ñ–Ñ… Ð¿Ð¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½ÑŒ.
"""

PUSH_WORDS = [
    "Ð·Ð°Ñ‚ÐºÐ½Ð¸ÑÑŒ", "Ð·Ð°Ð²Ð°Ð»Ð¸ÑÑŒ", "Ð¿Ñ€Ð¸Ð¿Ð¸Ð½Ð¸", "Ð´Ð¾ÑÐ¸Ñ‚ÑŒ",
    "Ð¿ÐµÑ€ÐµÐ³Ð½ÑƒÐ²", "Ñ‚Ð¾Ñ€Ð¼Ð¾Ð·Ð¸", "Ð²Ñ–Ð´Ð²Ð°Ð»Ð¸", "Ð·Ð°ÐºÑ€Ð¸Ð¹ÑÑ"
]

def is_push(text: str) -> bool:
    return any(w in text.lower() for w in PUSH_WORDS)

def is_calling_bot(text: str, username: str) -> bool:
    t = text.lower()
    return (
        "Ð±Ð¾Ñ‚" in t or
        "Ñ–Ð³Ð½Ð°Ñ‚" in t or
        (username and f"@{username.lower()}" in t)
    )

def format_context():
    lines = []
    for name, txt in chat_memory:
        if txt:
            lines.append(f"{name}: {txt}")
    return "\n".join(lines[-CONTEXT_N:])

async def generate_reply(context: str, last_text: str):
    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": f"ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:\n{context}\n\nÐžÑÑ‚Ð°Ð½Ð½Ñ”:\n{last_text}\n\nÐ’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾."}
        ],
        temperature=1.2,
        max_tokens=90,
        presence_penalty=0.8,
        frequency_penalty=0.6,
    )
    return resp.choices[0].message.content.strip()

def split_lines(text: str):
    raw = text.replace("\r", "\n").strip()
    if not raw:
        return ["Ð¢Ð° ÑˆÐ¾ Ñ‚Ð¸ Ð¼ÐµÐ»ÐµÑˆ, Ñ…ÑƒÐ¹ Ð¼Ð¾Ñ€Ð¶Ð¾Ð²Ð¸Ð¹?"]

    parts = [p.strip() for p in raw.split("\n") if p.strip()]

    if len(parts) == 1:
        tmp = raw.replace("! ", "!\n").replace("? ", "?\n").replace(". ", ".\n")
        parts = [p.strip() for p in tmp.split("\n") if p.strip()]

    trimmed = []
    for p in parts:
        if len(p) > MAX_CHARS_PER_LINE:
            p = p[:MAX_CHARS_PER_LINE] + "â€¦"
        trimmed.append(p)

    r = random.random()
    limit = 1 if r < 0.55 else (2 if r < 0.9 else 3)

    return trimmed[:min(limit, MAX_REPLY_LINES)]

# ==========================
# HANDLER
# ==========================

@dp.message()
async def handle_message(message: Message):
    global active_until, mute_until

    if message.chat.type not in ["group", "supergroup"]:
        return
    if not message.text:
        return

    now = time.time()
    text = message.text.strip()
    low = text.lower()

    user = message.from_user
    name = user.full_name or user.username or "Ð¥Ñ‚Ð¾ÑÑŒ"
    chat_memory.append((name, text))

    # ðŸ”¥ Ð¡ÐŸÐ•Ð¦Ð¢Ð Ð˜Ð“Ð•Ð  ÐÐ ÐŸÐ£Ð¢Ð†ÐÐ
    if "Ð¿ÑƒÑ‚Ñ–Ð½" in low:
        await message.reply("ÐŸÑƒÑ‚Ñ–Ð½ â€” Ð¿Ñ–Ð´Ð°Ñ€Ð°Ñ.")
        return

    if now < mute_until:
        return

    if is_push(low):
        await message.reply(random.choice([
            "Ð¢Ð° Ð¾Ðº, Ð¼Ð¾Ð²Ñ‡Ñƒ.",
            "Ð—Ð´ÑƒÐ²ÑÑ, Ð·Ð°Ð´Ð¾Ð²Ð¾Ð»ÐµÐ½Ñ–?",
            "Ð’ÑÐµ, Ð·Ð°ÐºÑ€Ð¸Ð²ÑÑ."
        ]))
        mute_until = now + MUTE_SECONDS
        active_until = 0
        return

    me = await bot.me()
    username = me.username or ""

    called = is_calling_bot(low, username)

    if called:
        await asyncio.sleep(random.randint(2, 5))
        ctx = format_context()
        reply = await generate_reply(ctx, text)
        for line in split_lines(reply):
            await message.reply(line)
            await asyncio.sleep(random.randint(1, 2))
        active_until = now + ACTIVE_WINDOW
        return

    if now < active_until:
        await asyncio.sleep(random.randint(2, 5))
        ctx = format_context()
        reply = await generate_reply(ctx, text)
        for line in split_lines(reply):
            await message.reply(line)
            await asyncio.sleep(random.randint(1, 2))
        return

    if random.random() < REPLY_CHANCE:
        await asyncio.sleep(random.randint(2, 5))
        ctx = format_context()
        reply = await generate_reply(ctx, text)
        for line in split_lines(reply):
            await message.reply(line)
            await asyncio.sleep(random.randint(1, 2))
        active_until = now + ACTIVE_WINDOW

# ==========================
# START
# ==========================

async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
